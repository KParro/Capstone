{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19da908e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from matplotlib import pyplot\n",
    "from pandas.plotting import scatter_matrix\n",
    "from sklearn import linear_model, metrics, model_selection\n",
    "\n",
    "# List location of the data file being imported.\n",
    "url = \"HR Employee Attrition.csv\"\n",
    "\n",
    "# List all column names in order used by the CSV file.\n",
    "names = ['Age', 'Attrition', 'BusinessTravel', 'DailyRate', 'Department', 'DistanceFromHome',\n",
    "     'Education', 'EducationField', 'EmployeeCount', 'EmployeeNumber',\n",
    "     'EnvironmentSatisfaction', 'Gender', 'HourlyRate', 'JobInvolvement', 'JobLevel',\n",
    "     'JobRole', 'JobSatisfaction', 'MaritalStatus', 'MonthlyIncome', 'MonthlyRate',\n",
    "     'NumCompaniesWorked', 'Over18', 'OverTime', 'PercentSalaryHike',\n",
    "     'PerformanceRating', 'RelationshipSatisfaction', 'StandardHours',\n",
    "     'StockOptionLevel', 'TotalWorkingYears', 'TrainingTimesLastYear',\n",
    "     'WorkLifeBalance', 'YearsAtCompany', 'YearsInCurrentRole',\n",
    "     'YearsSinceLastPromotion', 'YearsWithCurrManager']\n",
    "\n",
    "# Read data set into data frame and establish column names. Create a duplicate data frame called df_test to alter.\n",
    "df = pd.read_csv(url, names=names)\n",
    "df_test = df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8156b895",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For ease of testing different data, a line has been written to drop all columns so that the columns to keep can be\n",
    "# commented out. Note that the indices used to pull X & y values could need to be updated with each change.\n",
    "df_test = df_test.drop('Age', axis=1)\n",
    "# df_test = df_test.drop('Attrition', axis=1)\n",
    "df_test = df_test.drop('BusinessTravel', axis=1)\n",
    "df_test = df_test.drop('DailyRate', axis=1)\n",
    "df_test = df_test.drop('Department', axis=1)\n",
    "df_test = df_test.drop('DistanceFromHome', axis=1)\n",
    "df_test = df_test.drop('Education', axis=1)\n",
    "df_test = df_test.drop('EducationField', axis=1)\n",
    "df_test = df_test.drop('EmployeeCount', axis=1)\n",
    "df_test = df_test.drop('EmployeeNumber', axis=1)\n",
    "# df_test = df_test.drop('EnvironmentSatisfaction', axis=1)\n",
    "df_test = df_test.drop('Gender', axis=1)\n",
    "df_test = df_test.drop('HourlyRate', axis=1)\n",
    "# df_test = df_test.drop('JobInvolvement', axis=1)\n",
    "df_test = df_test.drop('JobLevel', axis=1)\n",
    "df_test = df_test.drop('JobRole', axis=1)\n",
    "# df_test = df_test.drop('JobSatisfaction', axis=1)\n",
    "df_test = df_test.drop('MaritalStatus', axis=1)\n",
    "df_test = df_test.drop('MonthlyIncome', axis=1)\n",
    "df_test = df_test.drop('MonthlyRate', axis=1)\n",
    "df_test = df_test.drop('NumCompaniesWorked', axis=1)\n",
    "df_test = df_test.drop('Over18', axis=1)\n",
    "df_test = df_test.drop('OverTime', axis=1)\n",
    "df_test = df_test.drop('PercentSalaryHike', axis=1)\n",
    "# df_test = df_test.drop('PerformanceRating', axis=1)\n",
    "df_test = df_test.drop('RelationshipSatisfaction', axis=1)\n",
    "df_test = df_test.drop('StandardHours', axis=1)\n",
    "df_test = df_test.drop('StockOptionLevel', axis=1)\n",
    "df_test = df_test.drop('TotalWorkingYears', axis=1)\n",
    "df_test = df_test.drop('TrainingTimesLastYear', axis=1)\n",
    "# df_test = df_test.drop('WorkLifeBalance', axis=1)\n",
    "df_test = df_test.drop('YearsAtCompany', axis=1)\n",
    "df_test = df_test.drop('YearsInCurrentRole', axis=1)\n",
    "df_test = df_test.drop('YearsSinceLastPromotion', axis=1)\n",
    "df_test = df_test.drop('YearsWithCurrManager', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4096e8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Establishes Logistic Regression Model and the x & y values. X is the kept indicators from data and y is attrition.\n",
    "# Also establishes a test data set by splitting the full data into 70% train and 30% test\n",
    "mylog_model = linear_model.LogisticRegression(max_iter=2000)\n",
    "\n",
    "y = df_test.values[:, 0]\n",
    "X = df_test.values[:, 1:35]\n",
    "X_train, X_test, y_train, y_test = model_selection.train_test_split(X, y, test_size=.3)\n",
    "\n",
    "mylog_model.fit(X_train, y_train)\n",
    "\n",
    "y_prediction = mylog_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5f0b847",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test and print the accuracy of the model using the previously established test data.\n",
    "accuracy = metrics.accuracy_score(y_test, y_prediction)\n",
    "accuracy = accuracy*100\n",
    "\n",
    "print(\"The model has an accuracy of {}\".format(round(accuracy, 2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54e3448e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print a confusion matrix using the previously established test data.\n",
    "print(metrics.plot_confusion_matrix(mylog_model, X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0bb5f49",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Establish and print a horizontal bar chart of the reports of Work Life Balance in the data set.\n",
    "import matplotlib.pyplot as plt\n",
    "def bar_charth(numbers, labels, pos):\n",
    "    plt.barh(pos, numbers, color='green')\n",
    "    plt.yticks(ticks=pos, labels=labels)\n",
    "    plt.show()\n",
    "    \n",
    "if __name__ == '__main__':\n",
    "    hNumbers = [ df['WorkLifeBalance'].value_counts()[1] , df['WorkLifeBalance'].value_counts()[2], df['WorkLifeBalance'].value_counts()[3], df['WorkLifeBalance'].value_counts()[4]]\n",
    "    hLabels = ['Lowest', 'Low', 'High', 'Highest']\n",
    "    pos = list(range(4))\n",
    "    bar_charth(hNumbers, hLabels, pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "633eeede",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Establish and print a bar graph of the reports of Job Satisfaction in the data set\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def bar_chart(numbers, labels, pos):\n",
    "    plt.bar(pos, numbers, color='blue')\n",
    "    plt.xticks(ticks=pos, labels=labels)\n",
    "    plt.title('Reports of Job Satisfaction')\n",
    "    plt.xlabel('Job Satisfaction')\n",
    "    plt.ylabel('Number of Employees')\n",
    "    plt.show()\n",
    "    \n",
    "if __name__ == '__main__':\n",
    "    sNumbers = [ df['JobSatisfaction'].value_counts()[1] , df['JobSatisfaction'].value_counts()[2], df['JobSatisfaction'].value_counts()[3], df['JobSatisfaction'].value_counts()[4]]\n",
    "    sLabels = ['Lowest', 'Low', 'High', 'Highest']\n",
    "    sPos = list(range(4))\n",
    "    bar_chart(sNumbers, sLabels, sPos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52536c8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Establish and print a pie chart of the Attrition reported in the data set. \n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "def pie_chart():\n",
    "    numbers = [df['Attrition'].value_counts()['Yes'] , df['Attrition'].value_counts()['No']]\n",
    "    labels = ['Attrition', 'Not Attrition']\n",
    "\n",
    "    explode = (0.1, 0)\n",
    "    fig1, ax1 = plt.subplots()\n",
    "    ax1.pie(numbers, explode=explode, labels=labels,\n",
    "            shadow=True, startangle=90,\n",
    "            autopct='%1.1f%%')\n",
    "    ax1.axis('equal')\n",
    "    plt.title('Attrition Percentage')\n",
    "    plt.show()\n",
    "if __name__ == '__main__':\n",
    "    pie_chart()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08a2ad3d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Print user commands for a prediction to be made and take in user input.\n",
    "value = input(\"Enter the user Environment Satisfaction, Job Involvement, Job Satisfaction, Performance Rating, and Work Life Balance \\n as reported by the latest employee survey. Remember that all values are rated 1 through 4. \\n Enter them in order seperated by a space. \\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f19b4911",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Print prediction based on user input.\n",
    "valueList = list(value.split(\" \"))\n",
    "print('If Yes is displayed then the employee is at risk of attrition. If No is displayed then there is no risk of attrition.')\n",
    "print(mylog_model.predict([valueList]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "93a6c605",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (3369374835.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"C:\\Users\\Kevin\\AppData\\Local\\Temp\\ipykernel_13584\\3369374835.py\"\u001b[1;36m, line \u001b[1;32m1\u001b[0m\n\u001b[1;33m    mamba install -c conda-forge voila\u001b[0m\n\u001b[1;37m          ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "027dfd64",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
